# 5A
# Usage of Sigmoid activation function in artificial neural
# network
import numpy as np

def percept(w, bias, x):
    model = np.dot(x, w) + bias
    logit = 1 / (1 + np.exp(-model))
    return np.round(logit)

def compute(name):
  weights = [logic[name][w] for w in logic[name]]
  output = [percept(weights, logic['bias'][name], val) for val in dataset]
  return name, output

logic = {
        'logic_and' : {
            'w0': -0.1,
            'w1': 0.2,
            'w2': 0.2
        },
        'logic_or': {
            'w0': -0.1,
            'w1': 0.7,
            'w2': 0.7
        },
        'logic_not': {
            'w0': 0.5,
            'w1': -0.7
        },
        'logic_nand': {
            'w0': 0.6,
            'w1': -0.8,
            'w2': -0.8
        },
        'logic_nor': {
            'w0': 0.5,
            'w1': -0.7,
            'w2': -0.7
        },
        'logic_xor': {
            'w0': -5,
            'w1': 20,
            'w2': 10
        },
        'logic_xnor': {
            'w0': -5,
            'w1': 20,
            'w2': 10
        },
        'bias': {
            'logic_and': -0.2,
            'logic_or': -0.1,
            'logic_not': 0.1,
            'logic_xor': 1,
            'logic_xnor': 1,
            'logic_nand': 0.3,
            'logic_nor': 0.1
        }
    }
dataset = [
    [1,0,0],
    [1,0,1],
    [1,1,0],
    [1,1,1]
]

name, new_logic = compute('logic_and')

def template(data):
    toPrint = [f"{datas[0]}   {datas[1]}   {datas[2]}   {output}  " for datas, output in zip(dataset, data)]
    for i in toPrint:
        print(i)

print(f"Logic Function: {name}")
print("X0  X1  X2  Y")
for logic_gate in new_logic:
    template([logic_gate])
